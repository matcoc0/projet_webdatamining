{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Part 1 - Web scrapping and knowledge base construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the CoNLL-2003 dataset\n",
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "# Access the training, validation, and test sets\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Example: Print the first example from the training set\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import inflect, string\n",
    "\n",
    "def write_numbers(text: str):\n",
    "\tp = inflect.engine()\n",
    "\twords = text.split()\n",
    "\tfor i, word in enumerate(words):\n",
    "\t\tif word.isdigit():\n",
    "\t\t\twords[i] = p.number_to_words(word)\n",
    "\n",
    "\treturn ' '.join(words)\n",
    "\n",
    "def remove_punctuation(text: str):\n",
    "\ttext = text.replace('-', ' ')\n",
    "\ttranslator = str.maketrans('', '', string.punctuation)\n",
    "\ttext = text.translate(translator)\n",
    "\treturn text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "def stem_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return ' '.join(stems)\n",
    "\n",
    "def lemma_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\n",
      "Japan began defence Asian Cup title lucky two one win Syria Group C championship match Friday\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text: str):\n",
    "\t# Remove punctuation\n",
    "\ttext = remove_punctuation(text)\n",
    "\n",
    "\t# Convert numbers to words\n",
    "\ttext = write_numbers(text)\n",
    "\n",
    "\t# Lowercase the text\n",
    "\t# text = text.lower()\n",
    "\t\n",
    "\t# Remove stopwords\n",
    "\ttext = remove_stopwords(text)\n",
    "\n",
    "\t# Stem the words\n",
    "\t# text = stem_words(text)\n",
    "\n",
    "\t# Lemmatize the words\n",
    "\ttext = lemma_words(text)\n",
    "\n",
    "\treturn text\n",
    "\n",
    "text = ' '.join(test_dataset[3]['tokens'])\n",
    "print(text)\n",
    "print(preprocess_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCyʼs en_ner_conll03 pre-trained NER model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Documents\\Julien\\Documents\\!ESILV\\A4\\! S8\\Web datamining & semantics\\Project\\.web_proj_env\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.7.5 and may not be 100% compatible with the current version (3.8.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\n",
      "Japan began defence Asian Cup title lucky two one win Syria Group C championship match Friday\n",
      "[('Japan', 'LOC'), ('Asian Cup', 'MISC'), ('Syria Group', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_types(text: str):\n",
    "\t# Load the spaCy model\n",
    "\tnlp = spacy.load(\"./best_ner_model\")\n",
    "\n",
    "\t# Create a spaCy Doc object\n",
    "\tdoc = nlp(text)\n",
    "\n",
    "\t# Extract named entities and their labels\n",
    "\tentities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "\treturn entities\n",
    "\n",
    "# Example usage\n",
    "text = ' '.join(test_dataset[3]['tokens'])\n",
    "clean_text = preprocess_text(text)\n",
    "# clean_text = ' '.join(tokens)\n",
    "entities = extract_types(clean_text)\n",
    "print(text)\n",
    "print(clean_text)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRF (Conditional Random Fields) model using sklearn-crfsuite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.89      0.78      0.83      1668\n",
      "      B-MISC       0.83      0.67      0.74       702\n",
      "       B-ORG       0.81      0.55      0.66      1661\n",
      "       B-PER       0.74      0.43      0.55      1617\n",
      "       I-LOC       0.42      0.66      0.51       257\n",
      "      I-MISC       0.63      0.60      0.61       216\n",
      "       I-ORG       0.53      0.63      0.58       835\n",
      "       I-PER       0.72      0.55      0.62      1156\n",
      "           O       0.94      0.97      0.95     38323\n",
      "\n",
      "    accuracy                           0.91     46435\n",
      "   macro avg       0.72      0.65      0.67     46435\n",
      "weighted avg       0.90      0.91      0.90     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import defaultdict\n",
    "\n",
    "tag_map = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}\n",
    "\n",
    "def extract_features(tokens):\n",
    "\treturn [{'word': token} for token in tokens]\n",
    "\n",
    "def get_labels(dataset):\n",
    "\treturn [[tag_map[tag] for tag in example['ner_tags']] for example in dataset]\n",
    "\n",
    "# Define the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "\talgorithm='lbfgs',\n",
    "\tc1=0.1,\n",
    "\tc2=0.1,\n",
    "\tmax_iterations=100,\n",
    "\tall_possible_transitions=False\n",
    ")\n",
    "\n",
    "# Extract features and labels for training and testing\n",
    "X_train = [extract_features(example['tokens']) for example in train_dataset]\n",
    "y_train = get_labels(train_dataset)\n",
    "X_test = [extract_features(example['tokens']) for example in test_dataset]\n",
    "y_test = get_labels(test_dataset)\n",
    "\n",
    "# Train the CRF model\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Metrics by Entity Type:\n",
      "--------------------------------------------------\n",
      "Entity     Precision    Recall       F1-Score    \n",
      "--------------------------------------------------\n",
      "LOC        0.65         0.72         0.67        \n",
      "MISC       0.73         0.63         0.68        \n",
      "PER        0.73         0.49         0.59        \n",
      "ORG        0.67         0.59         0.62        \n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store metrics for each entity type\n",
    "entity_metrics = defaultdict(list)\n",
    "\n",
    "# Get the report as a dictionary\n",
    "report = metrics.flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract metrics for each entity type\n",
    "for label, scores in report.items():\n",
    "\tif label.startswith('B-') or label.startswith('I-'):\n",
    "\t\tentity_type = label.split('-')[1]  # Extract LOC, MISC, PER, ORG\n",
    "\t\tif isinstance(scores, dict):\n",
    "\t\t\tfor metric, value in scores.items():\n",
    "\t\t\t\tif metric in ['precision', 'recall', 'f1-score']:\n",
    "\t\t\t\t\tentity_metrics[(entity_type, metric)].append(value)\n",
    "\n",
    "# Calculate mean metrics for each entity type\n",
    "entity_means = {}\n",
    "for (entity_type, metric), values in entity_metrics.items():\n",
    "\tif values:\n",
    "\t\tentity_means[(entity_type, metric)] = sum(values) / len(values)\n",
    "\n",
    "# Print the mean metrics for each entity type\n",
    "print(\"\\nMean Metrics by Entity Type:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Entity':<10} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "print(\"-\" * 50)\n",
    "for entity_type in ['LOC', 'MISC', 'PER', 'ORG']:\n",
    "\tprecision = entity_means.get((entity_type, 'precision'), 0)\n",
    "\trecall = entity_means.get((entity_type, 'recall'), 0)\n",
    "\tf1 = entity_means.get((entity_type, 'f1-score'), 0)\n",
    "\tprint(f\"{entity_type:<10} {precision:<12.2f} {recall:<12.2f} {f1:<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '3', 'tokens': ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.'], 'pos_tags': [22, 38, 12, 21, 15, 29, 16, 22, 21, 15, 12, 16, 11, 41, 15, 22, 15, 12, 22, 22, 21, 21, 15, 22, 7], 'chunk_tags': [11, 21, 11, 12, 13, 11, 12, 12, 12, 13, 11, 12, 12, 21, 13, 11, 13, 11, 12, 12, 12, 12, 13, 11, 0], 'ner_tags': [5, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "[['B-LOC' 'O' 'O' 'O' 'O' 'O' 'B-MISC' 'I-MISC' 'O' 'O' 'O' 'O' 'O' 'O'\n",
      "  'O' 'B-LOC' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[3])\n",
    "print(crf.predict([extract_features(test_dataset[3]['tokens'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation Extraction (RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan began defence Asian Cup title lucky two one win Syria Group C championship match Friday\n",
      "[('Japan', 'began', 'championship C win match')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_relations(text):\n",
    "\t# Load spaCy's pre-trained model\n",
    "\tnlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\t# Process the text with spaCy\n",
    "\tdoc = nlp(text)\n",
    "\n",
    "\t# Extract relations\n",
    "\trelations = []\n",
    "\tfor token in doc:\n",
    "\t\t# Subject-Verb-Object pattern\n",
    "\t\tif token.dep_ in (\"nsubj\", \"nsubjpass\"):\n",
    "\t\t\tsubject = token.text\n",
    "\t\t\t# Get the full subject phrase\n",
    "\t\t\tfor child in token.children:\n",
    "\t\t\t\tif child.dep_ in (\"compound\", \"amod\"):\n",
    "\t\t\t\t\tsubject = child.text + \" \" + subject\n",
    "\t\t\t\n",
    "\t\t\tif token.head.pos_ == \"VERB\":\n",
    "\t\t\t\tpredicate = token.head.text\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Look for objects\n",
    "\t\t\t\tfor child in token.head.children:\n",
    "\t\t\t\t\t# Direct object\n",
    "\t\t\t\t\tif child.dep_ == \"dobj\":\n",
    "\t\t\t\t\t\tobj = child.text\n",
    "\t\t\t\t\t\t# Get the full object phrase\n",
    "\t\t\t\t\t\tfor obj_child in child.children:\n",
    "\t\t\t\t\t\t\tif obj_child.dep_ in (\"compound\", \"amod\"):\n",
    "\t\t\t\t\t\t\t\tobj = obj_child.text + \" \" + obj\n",
    "\t\t\t\t\t\trelations.append((subject, predicate, obj))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Prepositional object\n",
    "\t\t\t\t\telif child.dep_ in (\"prep\", \"agent\"):\n",
    "\t\t\t\t\t\tfor pobj in child.children:\n",
    "\t\t\t\t\t\t\tif pobj.dep_ == \"pobj\":\n",
    "\t\t\t\t\t\t\t\tobj = pobj.text\n",
    "\t\t\t\t\t\t\t\t# Get full object phrase\n",
    "\t\t\t\t\t\t\t\tfor pobj_child in pobj.children:\n",
    "\t\t\t\t\t\t\t\t\tif pobj_child.dep_ in (\"compound\", \"amod\"):\n",
    "\t\t\t\t\t\t\t\t\t\tobj = pobj_child.text + \" \" + obj\n",
    "\t\t\t\t\t\t\t\t# Include the preposition in the relation\n",
    "\t\t\t\t\t\t\t\tfull_predicate = predicate + \" \" + child.text\n",
    "\t\t\t\t\t\t\t\trelations.append((subject, full_predicate, obj))\n",
    "\treturn relations\n",
    "\n",
    "# Test with an example\n",
    "text = ' '.join(test_dataset[3]['tokens'])\n",
    "clean_text = preprocess_text(text)\n",
    "relations = extract_relations(clean_text)\n",
    "print(clean_text)\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<rdf:RDF\n",
      "   xmlns:ns1=\"http://example.org/\"\n",
      "   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      ">\n",
      "  <rdf:Description rdf:about=\"http://example.org/Japan\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Location\"/>\n",
      "    <ns1:began rdf:resource=\"http://example.org/championship_C_win_match\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Asian_Cup\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Miscellaneous\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Syria_Group\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "</rdf:RDF>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "\n",
    "def create_graph(text):\n",
    "\t# Create a new RDF graph\n",
    "\tg = Graph()\n",
    "\n",
    "\t# Define namespaces\n",
    "\tEX = Namespace(\"http://example.org/\")\n",
    "\n",
    "\t# Preprocess the text\n",
    "\ttext = preprocess_text(text)\n",
    "\n",
    "\t# Add triples to the graph\n",
    "\t# Add types\n",
    "\tentities = extract_types(text)\n",
    "\n",
    "\tfor entity in entities:\n",
    "\t\tvalue = entity[0].replace(\" \", \"_\")\n",
    "\t\tif entity[1] == \"ORG\":\n",
    "\t\t\tg.add((URIRef(EX[value]), RDF.type, URIRef(EX.Company)))\n",
    "\t\telif entity[1] == \"PER\":\n",
    "\t\t\tg.add((URIRef(EX[value]), RDF.type, URIRef(EX.Person)))\n",
    "\t\telif entity[1] == \"LOC\":\n",
    "\t\t\tg.add((URIRef(EX[value]), RDF.type, URIRef(EX.Location)))\n",
    "\t\telif entity[1] == \"MISC\":\n",
    "\t\t\tg.add((URIRef(EX[value]), RDF.type, URIRef(EX.Miscellaneous)))\n",
    "\n",
    "\t# Add relations\n",
    "\trelations = extract_relations(text)\n",
    "\n",
    "\tfor relation in relations:\n",
    "\t\tsubject, predicate, obj = relation\n",
    "\t\tsubject = subject.replace(\" \", \"_\")\n",
    "\t\tpredicate = predicate.replace(\" \", \"_\")\n",
    "\t\tobj = obj.replace(\" \", \"_\")\n",
    "\n",
    "\t\tg.add((URIRef(EX[subject]), URIRef(EX[predicate]), URIRef(EX[obj])))\n",
    "\n",
    "\t# Serialize the graph in RDF/XML format\n",
    "\tgraph = g.serialize(format=\"xml\")\n",
    "\t\n",
    "\treturn g, graph\n",
    "\n",
    "text = ' '.join(test_dataset[3]['tokens'])\n",
    "g, graph = create_graph(text)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://example.org/Location \n",
      "http://example.org/began http://example.org/defence \n",
      "http://example.org/began_with http://example.org/lucky_win \n",
      "http://example.org/began_on http://example.org/Friday \n"
     ]
    }
   ],
   "source": [
    "# Perform a SPARQL query\n",
    "query = \"\"\"\n",
    "SELECT ?predicate ?object\n",
    "WHERE {\n",
    "  <http://example.org/Japan> ?predicate ?object .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "for row in g.query(query):\n",
    "\tprint(f\"{row.predicate} {row.object} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<rdf:RDF\n",
      "   xmlns:ns1=\"http://example.org/\"\n",
      "   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      ">\n",
      "  <rdf:Description rdf:about=\"http://example.org/Millennium_Falcon\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Movie\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Luke\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Chewbacca\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Location\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/specie\">\n",
      "    <ns1:known_for rdf:resource=\"http://example.org/whom\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Master_Yoda\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Jedi\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Star_Wars_IV\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "</rdf:RDF>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Star Wars IV is a Movie where there are different kinds of creatures, like\n",
    "humans and wookies. Some creatures are Jedis; for instance, the human Luke\n",
    "is a Jedi, and Master Yoda – for whom the species is not known – is also a\n",
    "Jedi. The wookie named Chewbacca is Han’s co-pilot on the Millennium\n",
    "Falcon starship. The speed of Millennium Falcon is 1.5 (above the speed of\n",
    "light!)\"\"\"\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "g, graph = create_graph(text)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Pipeline for Knowledge Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def fetch_reuters_articles():\n",
    "\t# Set up a user agent to mimic a browser\n",
    "\theaders = {\n",
    "\t\t'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "\t\t'Accept-Language': 'en-US,en;q=0.9',\n",
    "\t}\n",
    "\t\n",
    "\t# URL of Reuters World section\n",
    "\turl = \"https://www.reuters.com/world/\"\n",
    "\t\n",
    "\t# Make a request with the headers\n",
    "\tresponse = requests.get(url, headers=headers)\n",
    "\t\n",
    "\t# Parse the HTML content with BeautifulSoup\n",
    "\tsoup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\t\n",
    "\tarticles = []\n",
    "\t\n",
    "\tfor div in soup.find_all('div', {\"class\": \"media-story-card__body__3tRWy\"}, limit=10):\n",
    "\t\tpotential_articles = div.find_all('a')\n",
    "\t\tfor potential_article in potential_articles:\n",
    "\t\t\tif potential_article.parent.name != 'span':\n",
    "\t\t\t\tarticle = potential_article\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\ttitle = article.get_text()\n",
    "\t\t\n",
    "\t\tlink = article['href']\n",
    "\t\tarticle_url = f\"https://www.reuters.com{link}\"\n",
    "\t\t\n",
    "\t\tarticle_response = requests.get(article_url, headers=headers)\n",
    "\t\tarticle_soup = BeautifulSoup(article_response.content, 'html.parser')\n",
    "\n",
    "\t\t# Find all paragraphs in the article\n",
    "\t\tparagraphs = article_soup.find_all('div', {\"data-testid\": lambda value: value and value.startswith(\"paragraph-\")})\n",
    "\t\tcontent = '\\n'.join([p.get_text() for p in paragraphs])\n",
    "\t\t\n",
    "\t\tpublication_date = article_soup.find('meta', {'name': 'article:published_time'})['content']\n",
    "\n",
    "\t\tarticles.append({\n",
    "\t\t\t'title': title,\n",
    "\t\t\t'url': article_url,\n",
    "\t\t\t'content': content,\n",
    "\t\t\t'publication_date': publication_date\n",
    "\t\t})\n",
    "\n",
    "\treturn articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "articles = fetch_reuters_articles()\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 50 countries have contacted White House to start trade talks, Trump adviser says 2025-04-06T15:23:47Z\n",
      "WASHINGTON, April 6 - More than 50 countries have reached out to the White House to begin trade talks, a top economic adviser to U.S. President Donald Trump said on Sunday as U.S. officials sought to \n",
      "\n",
      "Iran wants indirect talks with US, warns regional countries over strikes against it 2025-04-06T09:58:30Z\n",
      "April 6 (Reuters) - Iran is pushing back against U.S. demands that it directly negotiate over its nuclear programme or be bombed, warning neighbours that host U.S. bases that they could be in the firi\n",
      "\n",
      "Israeli military changes initial account of Gaza aid worker killings 2025-04-06T11:30:26Z\n",
      "JERUSALEM, April 6 (Reuters) - The Israeli military has provided new details that changed its initial account of the killing of 15 emergency workers near the southern Gaza city of Rafah last month but\n",
      "\n",
      "Russian missile strike kills one, injures three in Kyiv, Ukraine says 2025-04-06T13:58:58Z\n",
      "KYIV, April 6 (Reuters) - A Russian missile attack on Kyiv killed one man and injured three other people overnight, causing damage and fires in several districts in the biggest such attack on Ukraine \n",
      "\n",
      "As judges stymie Trump with nationwide orders, pressure builds on US Supreme Court 2025-04-06T11:41:05Z\n",
      "WASHINGTON, April 6 (Reuters) - Republican President Donald Trump and his Democratic predecessor Joe Biden may not agree on much, but there is one issue on which they have been united: The need to blu\n",
      "\n",
      "EU seeks unity in first strike back at Trump tariffs 2025-04-06T13:07:36Z\n",
      "BRUSSELS, April 6 (Reuters) - European Union countries will seek to present a united front in the coming days against U.S. President Donald Trump's tariffs, likely approving a first set of targeted co\n",
      "\n",
      "Russian troops push into Ukraine's Sumy region 2025-04-06T11:55:46Z\n",
      "MOSCOW, April 6 (Reuters) - Russia said on Sunday that its troops had taken the village of Basivka in Ukraine's Sumy region, and were battering Ukrainian forces at a host of settlements in the area.\n",
      "M\n",
      "\n",
      "Netanyahu says will seek relief from tariffs in meeting with Trump 2025-04-06T12:56:36Z\n",
      "JERUSALEM, April 6 (Reuters) - Israeli Prime Minister Benjamin Netanyahu said on Sunday he hopes U.S. President Donald Trump will ease tariffs imposed on Israel when the two meet in Washington this we\n",
      "\n",
      "Le Pen evokes spirit of Martin Luther King Jr. as supporters rally in Paris 2025-04-06T14:30:57Z\n",
      "PARIS, April 6 (Reuters) - French far-right leader Marine Le Pen said on Sunday she would peacefully fight her five-year ban from running for office and draw inspiration from American civil rights lea\n",
      "\n",
      "Pope Francis makes surprise first appearance at Vatican after hospital stay 2025-04-06T11:57:56Z\n",
      "VATICAN CITY, April 6 (Reuters) - Pope Francis made his first public appearance since being discharged from hospital two weeks ago after treatment for double pneumonia, entering St. Peter's Square at \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in articles:\n",
    "\tprint(article['title'], article['publication_date'])\n",
    "\tprint(article['content'][:200]) # Print the first 200 characters of the content\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: More than 50 countries have contacted White House to start trade talks, Trump adviser says\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Select a random article\n",
    "random_article = random.choice(articles)\n",
    "\n",
    "print(\"Title:\", random_article['title'])\n",
    "content = random_article['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<rdf:RDF\n",
      "   xmlns:ns1=\"http://example.org/\"\n",
      "   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      ">\n",
      "  <rdf:Description rdf:about=\"http://example.org/Taiwanese\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Miscellaneous\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Federal_US_Reserve\">\n",
      "    <ns1:cut rdf:resource=\"http://example.org/interest_rate\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Scott_Secretary_Bessent\">\n",
      "    <ns1:downplayed_In rdf:resource=\"http://example.org/separate_interview\"/>\n",
      "    <ns1:downplayed rdf:resource=\"http://example.org/market_drop\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/US_Federal_Reserve\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Lai_Ching\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/based_tariff\">\n",
      "    <ns1:citing rdf:resource=\"http://example.org/job_US_anticipated_stronger_growth\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Bessent\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "    <ns1:told rdf:resource=\"http://example.org/NBC_News\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/levy_China\">\n",
      "    <ns1:sparking rdf:resource=\"http://example.org/war_fear_recession\"/>\n",
      "    <ns1:sparking_On rdf:resource=\"http://example.org/talk_morning_show\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Ching_Lai_President_te\">\n",
      "    <ns1:offered rdf:resource=\"http://example.org/basis_talk\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Truth_Social\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/US\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Location\"/>\n",
      "    <ns1:pledging rdf:resource=\"http://example.org/trade_remove_barrier\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/NBC_News\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/US_Sunday_official\">\n",
      "    <ns1:sought rdf:resource=\"http://example.org/defend\"/>\n",
      "    <ns1:sought rdf:resource=\"http://example.org/global_unleashed_sweeping_turmoil\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Scott_Bessent\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/growth_Tariff\">\n",
      "    <ns1:stunned rdf:resource=\"http://example.org/market_face\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/country\">\n",
      "    <ns1:reached rdf:resource=\"http://example.org/White_House\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/COVID\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Kevin_Hassett\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Hassett\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "    <ns1:told rdf:resource=\"http://example.org/ABC_News\"/>\n",
      "    <ns1:said_Unlike rdf:resource=\"http://example.org/economist\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/I\">\n",
      "    <ns1:see rdf:resource=\"http://example.org/price_reason_recession\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Donald_Trump\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/China\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Location\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/White_House\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Location\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/market_pressure\">\n",
      "    <ns1:cut rdf:resource=\"http://example.org/interest_rate\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Kevin_Director_Hassett\">\n",
      "    <ns1:denied_During rdf:resource=\"http://example.org/ABC_interview_News\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Unlike\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Taiwans\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Miscellaneous\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Taiwanese_company\">\n",
      "    <ns1:raise rdf:resource=\"http://example.org/US_investment\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/shared_video\">\n",
      "    <ns1:suggested_In rdf:resource=\"http://example.org/Social_Truth_post\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/WASHINGTON\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Trump\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Miscellaneous\"/>\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Trumps\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Person\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/We\">\n",
      "    <ns1:see rdf:resource=\"http://example.org/job_number\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Trump_top_official\">\n",
      "    <ns1:sought rdf:resource=\"http://example.org/tariff_portray_savvy\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/large_investor\">\n",
      "    <ns1:blamed rdf:resource=\"http://example.org/Trumps\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/jolted_based_economy\">\n",
      "    <ns1:announced rdf:resource=\"http://example.org/US_tariff_import\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/ABC_News_This\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/NBC_Newss_Meet_Press_US_Treasury\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/Tariff\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/analyst_aggressive_investor\">\n",
      "    <ns1:anticipating rdf:resource=\"http://example.org/It\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/US_National_Economic_Council\">\n",
      "    <rdf:type rdf:resource=\"http://example.org/Company\"/>\n",
      "  </rdf:Description>\n",
      "  <rdf:Description rdf:about=\"http://example.org/tariff\">\n",
      "    <ns1:driven rdf:resource=\"http://example.org/White_contact_House\"/>\n",
      "  </rdf:Description>\n",
      "</rdf:RDF>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g, graph = create_graph(content)\n",
    "print(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".web_proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
