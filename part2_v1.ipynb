{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daeb36fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (7.1.4)\n",
      "Requirement already satisfied: pykeen in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: torch in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: SPARQLWrapper in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rdflib) (3.1.4)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.6.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (1.14.1)\n",
      "Requirement already satisfied: click in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (8.1.7)\n",
      "Requirement already satisfied: click-default-group in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (1.2.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (4.66.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (2.32.3)\n",
      "Requirement already satisfied: optuna>=2.0.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (4.2.1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (2.2.3)\n",
      "Requirement already satisfied: tabulate in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.9.0)\n",
      "Requirement already satisfied: more-click in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.1.2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (10.6.0)\n",
      "Requirement already satisfied: pystow>=0.4.3 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.7.0)\n",
      "Requirement already satisfied: docdata in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.0.4)\n",
      "Requirement already satisfied: class-resolver>=0.5.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.5.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (6.0.2)\n",
      "Requirement already satisfied: torch-max-mem>=0.1.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.1.3)\n",
      "Requirement already satisfied: torch-ppr>=0.0.7 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (0.0.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pykeen) (4.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna>=2.0.0->pykeen) (1.15.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna>=2.0.0->pykeen) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna>=2.0.0->pykeen) (2.0.40)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->pykeen) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.0.0->pykeen) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->pykeen) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json->pykeen) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json->pykeen) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pykeen) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pykeen) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pykeen) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pykeen) (2025.1.31)\n",
      "Requirement already satisfied: Mako in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.3.9)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=2.0.0->pykeen) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ime cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Install required packages\n",
    "!pip install rdflib pykeen torch SPARQLWrapper scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3886ce3",
   "metadata": {},
   "source": [
    "## üîπ Load RDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"graph.xml\", format=\"xml\")\n",
    "triples = [(str(s), str(p), str(o)) for s, p, o in g]\n",
    "print(f\"Original triples: {len(triples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518c679",
   "metadata": {},
   "source": [
    "## üîπ Improved DBpedia Enrichment with Label Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152d30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered enriched triples: 202\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "\n",
    "def enrich_with_dbpedia(entity_name):\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?related ?relation WHERE {{\n",
    "        ?s rdfs:label \"{entity_name}\"@en .\n",
    "        ?s ?relation ?related .\n",
    "        ?related rdfs:label ?label .\n",
    "        FILTER(LANG(?label) = 'en')\n",
    "        FILTER NOT EXISTS {{\n",
    "            FILTER(\n",
    "                CONTAINS(STR(?relation), \"label\") ||\n",
    "                CONTAINS(STR(?relation), \"comment\") ||\n",
    "                CONTAINS(STR(?relation), \"type\") ||\n",
    "                CONTAINS(STR(?relation), \"isPrimaryTopicOf\") ||\n",
    "                CONTAINS(STR(?relation), \"sameAs\")\n",
    "            )\n",
    "        }}\n",
    "    }} LIMIT 10\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        return [\n",
    "            (f\"http://example.org/{entity_name}\", r['relation']['value'], r['related']['value'])\n",
    "            for r in results[\"results\"][\"bindings\"]\n",
    "        ]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Entities to enrich\n",
    "entities_to_enrich = [\n",
    "    \"Iran\", \"Trump\", \"Israel\", \"Reuters\", \"Iraq\", \"US\", \"Russia\", \"Yemen\", \"Gaza\", \"Khamenei\",\n",
    "    \"Syria\", \"Bahrain\", \"Lebanon\", \"Oman\", \"Qassem Soleimani\", \"Kuwait\", \"Qatar\", \"Turkey\",\n",
    "    \"Putin\", \"Tehran\", \"Baghdad\", \"Hezbollah\", \"UN\", \"China\", \"UAE\"\n",
    "]\n",
    "\n",
    "enriched_triples = []\n",
    "for entity in entities_to_enrich:\n",
    "    enriched_triples += enrich_with_dbpedia(entity)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"Filtered enriched triples: {len(enriched_triples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ff316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original triples: 84\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"graph.xml\", format=\"xml\")\n",
    "triples = [(str(s), str(p), str(o)) for s, p, o in g]\n",
    "print(f\"Original triples: {len(triples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac46e606",
   "metadata": {},
   "source": [
    "## üîπ Data Augmentation with DBpedia (Extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bba765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples after augmentation: 341\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "\n",
    "def enrich_with_dbpedia(entity_name):\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    query = f\"\"\"PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?related ?relation WHERE {{\n",
    "        ?s rdfs:label \"{entity_name}\"@en .\n",
    "        ?s ?relation ?related .\n",
    "    }} LIMIT 10\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        return [(f\"http://example.org/{entity_name}\", r['relation']['value'], r['related']['value']) for r in results[\"results\"][\"bindings\"]]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "entities_to_enrich = [\n",
    "    \"Iran\", \"Trump\", \"Israel\", \"Reuters\", \"Iraq\", \"US\", \"Russia\", \"Yemen\", \"Gaza\", \"Khamenei\",\n",
    "    \"Syria\", \"Bahrain\", \"Lebanon\", \"Oman\", \"Qassem Soleimani\", \"Kuwait\", \"Qatar\", \"Turkey\",\n",
    "    \"Putin\", \"Vladimir Putin\", \"Tehran\", \"Baghdad\", \"Hezbollah\", \"UN\", \"China\", \"UAE\"\n",
    "]\n",
    "enriched_triples = []\n",
    "for entity in entities_to_enrich:\n",
    "    enriched_triples += enrich_with_dbpedia(entity)\n",
    "    time.sleep(1)\n",
    "\n",
    "augmented_triples = triples + enriched_triples\n",
    "print(f\"Total triples after augmentation: {len(augmented_triples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4a7b6",
   "metadata": {},
   "source": [
    "## üîπ Add Inverse Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6806fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples after adding inverses: 682\n"
     ]
    }
   ],
   "source": [
    "inverse_triples = [(o, f\"inv_{p}\", s) for s, p, o in augmented_triples]\n",
    "augmented_triples += inverse_triples\n",
    "print(f\"Total triples after adding inverses: {len(augmented_triples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c27fe5",
   "metadata": {},
   "source": [
    "## üîπ Manual Train/Valid/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d3bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [315, 68, 68]\n"
     ]
    }
   ],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "tf = TriplesFactory.from_labeled_triples(triples_array)\n",
    "training, validation, testing = tf.split([0.8, 0.1, 0.1], random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a1cda",
   "metadata": {},
   "source": [
    "## üîπ Train RotatE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd9f76d",
   "metadata": {},
   "source": [
    "## üîπ Evaluation Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3deb1e8",
   "metadata": {},
   "source": [
    "## üîπ TSNE Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b853ca",
   "metadata": {},
   "source": [
    "## üîπ Multi-Model Training and Metric Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3871d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Using device: cpu\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-8d2321c2-3a59-460c-95e6-a39b73861866.pt\n",
      "Training epochs on cpu:   4%|‚ñç         | 9/200 [00:04<01:22,  2.32epoch/s, loss=0.0314, prev_loss=0.0345]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.8161764705882353. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-8d2321c2-3a59-460c-95e6-a39b73861866.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n",
      "Training epochs on cpu:  10%|‚ñâ         | 19/200 [00:09<01:26,  2.09epoch/s, loss=0.0333, prev_loss=0.0321]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 20: 0.8382352941176471. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-8d2321c2-3a59-460c-95e6-a39b73861866.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 20.\n",
      "Training epochs on cpu:  14%|‚ñà‚ñç        | 29/200 [00:16<01:40,  1.70epoch/s, loss=0.0244, prev_loss=0.0309]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "Training epochs on cpu:  20%|‚ñà‚ñâ        | 39/200 [00:21<01:12,  2.23epoch/s, loss=0.0334, prev_loss=0.0294]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 40: 0.8970588235294118. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-8d2321c2-3a59-460c-95e6-a39b73861866.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 40.\n",
      "Training epochs on cpu:  24%|‚ñà‚ñà‚ñç       | 49/200 [00:25<00:59,  2.55epoch/s, loss=0.0326, prev_loss=0.0364]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "Training epochs on cpu:  30%|‚ñà‚ñà‚ñâ       | 59/200 [00:29<00:53,  2.65epoch/s, loss=0.0272, prev_loss=0.0285]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "Training epochs on cpu:  34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:33<00:50,  2.58epoch/s, loss=0.03, prev_loss=0.0309]  WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "Training epochs on cpu:  40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:37<00:47,  2.56epoch/s, loss=0.0353, prev_loss=0.0369]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "Training epochs on cpu:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:41<00:45,  2.46epoch/s, loss=0.028, prev_loss=0.0292] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:Stopping early at epoch 90. The best result 0.8970588235294118 occurred at epoch 40.\n",
      "INFO:pykeen.stoppers.early_stopping:Re-loading weights from best epoch from C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-8d2321c2-3a59-460c-95e6-a39b73861866.pt\n",
      "Training epochs on cpu:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:41<00:52,  2.13epoch/s, loss=0.028, prev_loss=0.0292]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/68.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68.0/68.0 [00:00<00:00, 523triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "INFO:pykeen.pipeline.api:Using device: cpu\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "Training epochs on cpu:   4%|‚ñç         | 9/200 [00:06<01:52,  1.70epoch/s, loss=1.85, prev_loss=1.97]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.56s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.0. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n",
      "Training epochs on cpu:  10%|‚ñâ         | 19/200 [00:13<01:53,  1.60epoch/s, loss=0.442, prev_loss=0.501]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 20: 0.014705882352941176. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 20.\n",
      "Training epochs on cpu:  14%|‚ñà‚ñç        | 29/200 [00:19<01:45,  1.62epoch/s, loss=0.218, prev_loss=0.227]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 30: 0.07352941176470588. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 30.\n",
      "Training epochs on cpu:  20%|‚ñà‚ñâ        | 39/200 [00:25<01:24,  1.90epoch/s, loss=0.172, prev_loss=0.213]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "Training epochs on cpu:  24%|‚ñà‚ñà‚ñç       | 49/200 [00:30<01:21,  1.85epoch/s, loss=0.162, prev_loss=0.148]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 50: 0.08823529411764706. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 50.\n",
      "Training epochs on cpu:  30%|‚ñà‚ñà‚ñâ       | 59/200 [00:36<01:11,  1.96epoch/s, loss=0.158, prev_loss=0.16] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 60: 0.09558823529411764. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 60.\n",
      "Training epochs on cpu:  34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:41<01:16,  1.72epoch/s, loss=0.139, prev_loss=0.137]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 70: 0.11029411764705882. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 70.\n",
      "Training epochs on cpu:  40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:47<01:02,  1.92epoch/s, loss=0.142, prev_loss=0.146]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "Training epochs on cpu:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:52<00:57,  1.92epoch/s, loss=0.13, prev_loss=0.151] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 90: 0.125. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 90.\n",
      "Training epochs on cpu:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:58<00:55,  1.83epoch/s, loss=0.133, prev_loss=0.165]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 100: 0.14705882352941177. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 100.\n",
      "Training epochs on cpu:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [01:03<00:51,  1.75epoch/s, loss=0.139, prev_loss=0.147]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "Training epochs on cpu:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [01:09<00:46,  1.76epoch/s, loss=0.135, prev_loss=0.155]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 120: 0.16176470588235295. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 120.\n",
      "Training epochs on cpu:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [01:17<00:51,  1.39epoch/s, loss=0.156, prev_loss=0.143]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "Training epochs on cpu:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [01:23<00:37,  1.64epoch/s, loss=0.151, prev_loss=0.143]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "Training epochs on cpu:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [01:29<00:28,  1.81epoch/s, loss=0.159, prev_loss=0.15] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "Training epochs on cpu:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [01:35<00:22,  1.83epoch/s, loss=0.16, prev_loss=0.136] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "Training epochs on cpu:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [01:40<00:16,  1.91epoch/s, loss=0.153, prev_loss=0.152]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:Stopping early at epoch 170. The best result 0.16176470588235295 occurred at epoch 120.\n",
      "INFO:pykeen.stoppers.early_stopping:Re-loading weights from best epoch from C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-65445cb1-2934-4f0d-b765-3db7f1523462.pt\n",
      "Training epochs on cpu:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [01:40<00:18,  1.68epoch/s, loss=0.153, prev_loss=0.152]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/68.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68.0/68.0 [00:00<00:00, 642triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "INFO:pykeen.pipeline.api:Using device: cpu\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-4290e53d-a101-4192-b031-88d05c6399a0.pt\n",
      "Training epochs on cpu:   4%|‚ñç         | 9/200 [00:04<01:16,  2.49epoch/s, loss=0.0452, prev_loss=0.0675]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.8014705882352942. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-4290e53d-a101-4192-b031-88d05c6399a0.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n",
      "Training epochs on cpu:  10%|‚ñâ         | 19/200 [00:08<01:21,  2.21epoch/s, loss=0.028, prev_loss=0.0267] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 20: 0.8676470588235294. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-4290e53d-a101-4192-b031-88d05c6399a0.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 20.\n",
      "Training epochs on cpu:  14%|‚ñà‚ñç        | 29/200 [00:12<01:09,  2.45epoch/s, loss=0.0307, prev_loss=0.0263]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 30: 0.9044117647058824. Saved model weights to C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-4290e53d-a101-4192-b031-88d05c6399a0.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 30.\n",
      "Training epochs on cpu:  20%|‚ñà‚ñâ        | 39/200 [00:17<01:07,  2.40epoch/s, loss=0.0275, prev_loss=0.0268]WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "Training epochs on cpu:  24%|‚ñà‚ñà‚ñç       | 49/200 [00:21<01:00,  2.48epoch/s, loss=0.0237, prev_loss=0.024] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "Training epochs on cpu:  30%|‚ñà‚ñà‚ñâ       | 59/200 [00:25<01:02,  2.25epoch/s, loss=0.022, prev_loss=0.0264] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "Training epochs on cpu:  34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:30<00:53,  2.44epoch/s, loss=0.0243, prev_loss=0.027] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "Training epochs on cpu:  40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:35<00:56,  2.15epoch/s, loss=0.0245, prev_loss=0.021] WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:Stopping early at epoch 80. The best result 0.9044117647058824 occurred at epoch 30.\n",
      "INFO:pykeen.stoppers.early_stopping:Re-loading weights from best epoch from C:\\Users\\ime cj\\.data\\pykeen\\checkpoints\\best-model-weights-4290e53d-a101-4192-b031-88d05c6399a0.pt\n",
      "Training epochs on cpu:  40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:35<00:54,  2.24epoch/s, loss=0.0245, prev_loss=0.021]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/68.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68.0/68.0 [00:00<00:00, 358triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "import torch\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model in [\"TransE\", \"ComplEx\", \"RotatE\"]:\n",
    "    result = pipeline(\n",
    "        training=training,\n",
    "        validation=validation,\n",
    "        testing=testing,\n",
    "        model=model,\n",
    "        model_kwargs=dict(embedding_dim=128),\n",
    "        training_kwargs=dict(batch_size=32),\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=10),\n",
    "        optimizer_kwargs=dict(lr=0.005),\n",
    "        training_loop='slcwa',\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(patience=5),\n",
    "        epochs=200,\n",
    "        random_seed=42,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    )\n",
    "    model_results[model] = {\n",
    "        \"result\": result,\n",
    "        \"training\": training,\n",
    "        \"validation\": validation,\n",
    "        \"testing\": testing,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f4c8761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/68.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68.0/68.0 [00:00<00:00, 355triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.30s seconds\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/68.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68.0/68.0 [00:00<00:00, 824triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.09s seconds\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/68.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 68.0/68.0 [00:00<00:00, 918triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.09s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mean_rank  median_rank  hits_at_1  hits_at_5  hits_at_10\n",
      "TransE       None          2.0   0.477941   0.808824    0.889706\n",
      "ComplEx      None         68.0   0.036765   0.088235    0.139706\n",
      "RotatE       None          1.0   0.757353   0.867647    0.889706\n"
     ]
    }
   ],
   "source": [
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "evaluator = RankBasedEvaluator()\n",
    "manual_eval_data = {}\n",
    "\n",
    "for name, data in model_results.items():\n",
    "    result = data[\"result\"]\n",
    "    train = data[\"training\"].mapped_triples\n",
    "    valid = data[\"validation\"].mapped_triples\n",
    "    test = data[\"testing\"].mapped_triples\n",
    "\n",
    "    eval_result = evaluator.evaluate(\n",
    "        model=result.model,\n",
    "        mapped_triples=test,\n",
    "        additional_filter_triples=[train, valid]\n",
    "    )\n",
    "\n",
    "    df = eval_result.to_df()\n",
    "    filtered = df[(df[\"Rank_type\"] == \"realistic\") & (df[\"Side\"] == \"both\")]\n",
    "    metric_dict = filtered.set_index(\"Metric\")[\"Value\"].to_dict()\n",
    "\n",
    "    manual_eval_data[name] = {\n",
    "        \"mean_rank\": metric_dict.get(\"mean_rank\", None),\n",
    "        \"median_rank\": metric_dict.get(\"median_rank\", None),\n",
    "        \"hits_at_1\": metric_dict.get(\"hits_at_1\", None),\n",
    "        \"hits_at_5\": metric_dict.get(\"hits_at_5\", None),\n",
    "        \"hits_at_10\": metric_dict.get(\"hits_at_10\", None),\n",
    "    }\n",
    "\n",
    "\n",
    "manual_df = pd.DataFrame.from_dict(manual_eval_data, orient=\"index\")\n",
    "print(manual_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a4609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mean_rank mean_reciprocal_rank  hits_at_1  hits_at_3  hits_at_10\n",
      "Model                                                                   \n",
      "TransE       None                 None        0.0   0.007246    0.007246\n",
      "ComplEx      None                 None        0.0   0.021739    0.043478\n",
      "RotatE       None                 None        0.0   0.007246    0.028986\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "main_metrics = [\n",
    "    \"mean_rank\",\n",
    "    \"mean_reciprocal_rank\",\n",
    "    \"hits_at_1\",\n",
    "    \"hits_at_3\",\n",
    "    \"hits_at_10\"\n",
    "]\n",
    "\n",
    "eval_data = []\n",
    "Z\n",
    "for name, res in model_results.items():\n",
    "    df = res.metric_results.to_df()\n",
    "\n",
    "    # Filtrer uniquement realistic & both\n",
    "    filtered_df = df[(df[\"Rank_type\"] == \"realistic\") & (df[\"Side\"] == \"both\")]\n",
    "\n",
    "    # Extraire toutes les m√©triques disponibles pour cette config\n",
    "    metrics_dict = filtered_df.set_index(\"Metric\")[\"Value\"].to_dict()\n",
    "\n",
    "    # Ne garder que les m√©triques d'int√©r√™t\n",
    "    selected_metrics = {metric: metrics_dict.get(metric, None) for metric in main_metrics}\n",
    "\n",
    "    eval_data.append({\"Model\": name, **selected_metrics})\n",
    "\n",
    "comparison_df = DataFrame(eval_data).set_index(\"Model\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efb27095",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m embeddings_transe \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTransE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mentity_representations[\u001b[38;5;241m0\u001b[39m]()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m reduced_transe \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(embeddings_transe)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "embeddings_transe = model_results[\"TransE\"].model.entity_representations[0]().detach().cpu().numpy()\n",
    "reduced_transe = TSNE(n_components=2, random_state=42).fit_transform(embeddings_transe)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_transe[:, 0], reduced_transe[:, 1], alpha=0.6)\n",
    "plt.title(\"Entity Embeddings ‚Äî TransE\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e21c292",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n[[ 0.42304686-0.5920671j  -1.6153774 +0.2812441j   0.46541896+1.8071135j\n  ... -1.6575778 +0.19755676j -0.09239901+1.079247j\n   0.31102142-0.539822j  ]\n [ 2.8423007 -2.388127j    0.26689819+0.6929528j  -0.07349462+0.0500029j\n  ... -1.2875018 -0.06143591j -0.535237  +0.23292255j\n   0.6835749 -0.37317464j]\n [ 0.06837677-1.2175353j   1.9348993 +1.0373638j   1.9172271 +0.913429j\n  ...  0.41829148+2.1669295j   1.3658816 -1.5876018j\n   1.0856167 -0.2783503j ]\n ...\n [ 0.15198861+0.01087606j -0.11931475+0.1594931j   0.14988413+1.8060216j\n  ... -0.65802693+0.51673627j  0.30926955+0.13792837j\n   0.8022545 +1.1443865j ]\n [ 0.9876714 +1.0506305j   0.52220356-0.16624801j -0.05501075+0.22776593j\n  ...  0.39406368+0.17923695j  0.43722886-0.5934584j\n  -0.44031888+1.8269788j ]\n [-0.8972331 -0.19464134j -2.1231577 -0.7207148j  -1.1468089 -1.2249564j\n  ... -0.31524062-0.40659133j -1.8121793 +0.8618069j\n  -0.30118936-0.1091449j ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m embeddings_complex \u001b[38;5;241m=\u001b[39m model_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplEx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mentity_representations[\u001b[38;5;241m0\u001b[39m]()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m----> 2\u001b[0m reduced_complex \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_complex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(reduced_complex[:, \u001b[38;5;241m0\u001b[39m], reduced_complex[:, \u001b[38;5;241m1\u001b[39m], alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1176\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1176\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:884\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 884\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    892\u001b[0m         X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64]\n\u001b[0;32m    893\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1014\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m-> 1014\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# It is possible that the np.array(..) gave no warning. This happens\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# when no dtype conversion happened, for example dtype = None. The\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# result is that np.array(..) produces an array of complex dtype\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# and we need to catch and raise exception for such cases.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m _ensure_no_complex_data(array)\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n[[ 0.42304686-0.5920671j  -1.6153774 +0.2812441j   0.46541896+1.8071135j\n  ... -1.6575778 +0.19755676j -0.09239901+1.079247j\n   0.31102142-0.539822j  ]\n [ 2.8423007 -2.388127j    0.26689819+0.6929528j  -0.07349462+0.0500029j\n  ... -1.2875018 -0.06143591j -0.535237  +0.23292255j\n   0.6835749 -0.37317464j]\n [ 0.06837677-1.2175353j   1.9348993 +1.0373638j   1.9172271 +0.913429j\n  ...  0.41829148+2.1669295j   1.3658816 -1.5876018j\n   1.0856167 -0.2783503j ]\n ...\n [ 0.15198861+0.01087606j -0.11931475+0.1594931j   0.14988413+1.8060216j\n  ... -0.65802693+0.51673627j  0.30926955+0.13792837j\n   0.8022545 +1.1443865j ]\n [ 0.9876714 +1.0506305j   0.52220356-0.16624801j -0.05501075+0.22776593j\n  ...  0.39406368+0.17923695j  0.43722886-0.5934584j\n  -0.44031888+1.8269788j ]\n [-0.8972331 -0.19464134j -2.1231577 -0.7207148j  -1.1468089 -1.2249564j\n  ... -0.31524062-0.40659133j -1.8121793 +0.8618069j\n  -0.30118936-0.1091449j ]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_complex = model_results[\"ComplEx\"].model.entity_representations[0]().detach().cpu().numpy()\n",
    "reduced_complex = TSNE(n_components=2, random_state=42).fit_transform(embeddings_complex)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_complex[:, 0], reduced_complex[:, 1], alpha=0.6, color=\"orange\")\n",
    "plt.title(\"Entity Embeddings ‚Äî ComplEx\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_rotate = model_results[\"RotatE\"].model.entity_representations[0]().detach().cpu().numpy()\n",
    "reduced_rotate = TSNE(n_components=2, random_state=42).fit_transform(embeddings_rotate)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_rotate[:, 0], reduced_rotate[:, 1], alpha=0.6, color=\"green\")\n",
    "plt.title(\"Entity Embeddings ‚Äî RotatE\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
