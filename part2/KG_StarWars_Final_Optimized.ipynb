{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034ce49e",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Ã‰tape 1 â€” Installation des dÃ©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install spacy rdflib pykeen torch scikit-learn matplotlib\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af8a02",
   "metadata": {},
   "source": [
    "## ðŸ§  Ã‰tape 2 â€” Extraction automatique de relations depuis le .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f33ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 relations extraites\n",
      "('Ahsoka', 'is', 'Padawan')\n",
      "('R2D2', 'serve', 'Anakin')\n",
      "('Jabba', 'hire', 'BobaFett')\n",
      "('Lando', 'help', 'Chewbacca')\n",
      "('Finn', 'join', 'Resistance')\n",
      "('Han', 'pilot', 'MillenniumFalcon')\n",
      "('DeathStar', 'is', 'superweapon')\n",
      "('Luke', 'train', 'KyloRen')\n",
      "('ObiWan', 'train', 'Anakin')\n",
      "('PadmÃ©', 'is', 'wife')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def extract_all_relations(txt_path):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    doc = nlp(text)\n",
    "\n",
    "    relations = []\n",
    "\n",
    "    # 1. \"X is the Y of Z\"\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [\n",
    "        {\"DEP\": \"nsubj\"},\n",
    "        {\"LEMMA\": \"be\"},\n",
    "        {\"LOWER\": \"the\"},\n",
    "        {\"POS\": \"NOUN\"},\n",
    "        {\"LOWER\": \"of\"},\n",
    "        {\"DEP\": \"pobj\"},\n",
    "    ]\n",
    "    matcher.add(\"is_relation_of\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "    for _, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        relations.append((span[0].text, span[3].text, span[5].text))\n",
    "\n",
    "    # 2. \"X is Y\"\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"attr\" and token.head.lemma_ == \"be\":\n",
    "                subj = [t for t in token.head.children if t.dep_ == \"nsubj\"]\n",
    "                if subj:\n",
    "                    relations.append((subj[0].text, \"is\", token.text))\n",
    "\n",
    "    # 3. \"X verb Y\"\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.dep_ in (\"nsubj\", \"nsubjpass\") and token.head.pos_ == \"VERB\":\n",
    "                verb = token.head.lemma_\n",
    "                subject = token.text\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\", \"pobj\"):\n",
    "                        relations.append((subject, verb, child.text))\n",
    "\n",
    "    # 4. \"X was Vpp by Y\" (voix passive)\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubjpass\" and token.head.pos_ == \"VERB\":\n",
    "                verb = token.head.lemma_\n",
    "                object_ = token.text\n",
    "                agent = [child for child in token.head.children if child.dep_ == \"agent\"]\n",
    "                if agent:\n",
    "                    by_obj = [t for t in agent[0].children if t.dep_ == \"pobj\"]\n",
    "                    if by_obj:\n",
    "                        relations.append((by_obj[0].text, verb, object_))\n",
    "\n",
    "    # 5. \"X verb with Y\" â†’ ex: \"Mando travels with Grogu\"\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"VERB\":\n",
    "                subject = [t for t in token.children if t.dep_ == \"nsubj\"]\n",
    "                prep_with = [t for t in token.children if t.dep_ == \"prep\" and t.text == \"with\"]\n",
    "                if subject and prep_with:\n",
    "                    pobj = [t for t in prep_with[0].children if t.dep_ == \"pobj\"]\n",
    "                    if pobj:\n",
    "                        relations.append((subject[0].text, token.lemma_, pobj[0].text))\n",
    "\n",
    "    return list(set(relations))  # Ã©limine doublons\n",
    "\n",
    "# ðŸ“¥ Utilisation directe avec le fichier \"devtest.txt\"\n",
    "relations = extract_all_relations(\"devtest.txt\")\n",
    "print(f\"{len(relations)} relations extraites\")\n",
    "for r in relations[:10]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58404c06",
   "metadata": {},
   "source": [
    "## ðŸ§± Ã‰tape 3 â€” Construction du graphe RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51963038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de triplets RDF : 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(rdflib.term.URIRef('http://example.org/ObiWan'),\n",
       " rdflib.term.URIRef('http://example.org/train'),\n",
       " rdflib.term.URIRef('http://example.org/Anakin'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from rdflib import Graph, Namespace, RDF\n",
    "\n",
    "g = Graph()\n",
    "EX = Namespace(\"http://example.org/\")\n",
    "\n",
    "for s, p, o in relations:\n",
    "    g.add((EX[s], EX[p], EX[o]))\n",
    "\n",
    "print(\"Nombre de triplets RDF :\", len(g))\n",
    "next(iter(g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e038e",
   "metadata": {},
   "source": [
    "## ðŸ§ª Ã‰tape 4 â€” VÃ©rification de la couverture du graphe avant split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74f42b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'entitÃ©s : 49\n",
      "Nombre total de relations : 21\n",
      "Top 5 entitÃ©s : [(rdflib.term.URIRef('http://example.org/Leia'), 7), (rdflib.term.URIRef('http://example.org/Han'), 6), (rdflib.term.URIRef('http://example.org/Luke'), 6), (rdflib.term.URIRef('http://example.org/Anakin'), 5), (rdflib.term.URIRef('http://example.org/KyloRen'), 5)]\n",
      "Top 5 relations : [(rdflib.term.URIRef('http://example.org/is'), 19), (rdflib.term.URIRef('http://example.org/train'), 5), (rdflib.term.URIRef('http://example.org/lead'), 2), (rdflib.term.URIRef('http://example.org/help'), 2), (rdflib.term.URIRef('http://example.org/son'), 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "entities = []\n",
    "relations_set = []\n",
    "\n",
    "for s, p, o in g:\n",
    "    entities.extend([s, o])\n",
    "    relations_set.append(p)\n",
    "\n",
    "entity_counts = Counter(entities)\n",
    "relation_counts = Counter(relations_set)\n",
    "\n",
    "print(f\"Nombre total d'entitÃ©s : {len(set(entities))}\")\n",
    "print(f\"Nombre total de relations : {len(set(relations_set))}\")\n",
    "print(\"Top 5 entitÃ©s :\", entity_counts.most_common(5))\n",
    "print(\"Top 5 relations :\", relation_counts.most_common(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0d2b3",
   "metadata": {},
   "source": [
    "## ðŸ¤– Ã‰tape 5 â€” EntraÃ®nement du modÃ¨le TransE avec PyKEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba62cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=263303681\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find a coverage of all entities and relation with only 37 triples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m triples_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(triples, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m      7\u001b[0m full_tf \u001b[38;5;241m=\u001b[39m TriplesFactory\u001b[38;5;241m.\u001b[39mfrom_labeled_triples(triples_array)\n\u001b[1;32m----> 9\u001b[0m training, validation, testing \u001b[38;5;241m=\u001b[39m \u001b[43mfull_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     12\u001b[0m     training\u001b[38;5;241m=\u001b[39mtraining,\n\u001b[0;32m     13\u001b[0m     validation\u001b[38;5;241m=\u001b[39mvalidation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     20\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pykeen\\triples\\triples_factory.py:589\u001b[0m, in \u001b[0;36mCoreTriplesFactory.split\u001b[1;34m(self, ratios, random_state, randomize_cleanup, method)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Split a triples factory into a training part and a variable number of (transductive) evaluation parts.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m.. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    training_factory, testing_factory, validation_factory = factory.split(ratios)\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;66;03m# Make new triples factories for each group\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone_and_exchange_triples(\n\u001b[0;32m    584\u001b[0m         mapped_triples\u001b[38;5;241m=\u001b[39mtriples,\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;66;03m# do not explicitly create inverse triples for testing; this is handled by the evaluation code\u001b[39;00m\n\u001b[0;32m    586\u001b[0m         create_inverse_triples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, triples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m--> 589\u001b[0m         \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m            \u001b[49m\u001b[43mratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandomize_cleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomize_cleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m     )\n\u001b[0;32m    597\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pykeen\\triples\\splitting.py:524\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(mapped_triples, ratios, random_state, randomize_cleanup, method)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m splitter_cls \u001b[38;5;129;01mis\u001b[39;00m CleanupSplitter \u001b[38;5;129;01mand\u001b[39;00m randomize_cleanup:\n\u001b[0;32m    523\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaner\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaner_resolver\u001b[38;5;241m.\u001b[39mnormalize_cls(RandomizedCleaner)\n\u001b[1;32m--> 524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msplitter_resolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitter_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pykeen\\triples\\splitting.py:394\u001b[0m, in \u001b[0;36mSplitter.split\u001b[1;34m(self, mapped_triples, ratios, random_state)\u001b[0m\n\u001b[0;32m    392\u001b[0m ratios \u001b[38;5;241m=\u001b[39m normalize_ratios(ratios\u001b[38;5;241m=\u001b[39mratios)\n\u001b[0;32m    393\u001b[0m sizes \u001b[38;5;241m=\u001b[39m get_absolute_split_sizes(n_total\u001b[38;5;241m=\u001b[39mmapped_triples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], ratios\u001b[38;5;241m=\u001b[39mratios)\n\u001b[1;32m--> 394\u001b[0m triples_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_absolute_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (triples, exp_size, exp_ratio) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(triples_groups, sizes, ratios)):\n\u001b[0;32m    400\u001b[0m     actual_size \u001b[38;5;241m=\u001b[39m triples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ime cj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pykeen\\triples\\splitting.py:462\u001b[0m, in \u001b[0;36mCoverageSplitter.split_absolute_size\u001b[1;34m(self, mapped_triples, sizes, random_state)\u001b[0m\n\u001b[0;32m    460\u001b[0m remaining_triples \u001b[38;5;241m=\u001b[39m mapped_triples[\u001b[38;5;241m~\u001b[39mseed_mask]\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_seed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m sizes[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a coverage of all entities and relation with only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m triples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    463\u001b[0m remaining_sizes \u001b[38;5;241m=\u001b[39m (sizes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m train_seed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sizes[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    464\u001b[0m train, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m _split_triples(\n\u001b[0;32m    465\u001b[0m     mapped_triples\u001b[38;5;241m=\u001b[39mremaining_triples,\n\u001b[0;32m    466\u001b[0m     sizes\u001b[38;5;241m=\u001b[39mremaining_sizes,\n\u001b[0;32m    467\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m    468\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not find a coverage of all entities and relation with only 37 triples."
     ]
    }
   ],
   "source": [
    "\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "import numpy as np\n",
    "\n",
    "triples = [(str(s), str(p), str(o)) for s, p, o in g]\n",
    "triples_array = np.array(triples, dtype=str)\n",
    "full_tf = TriplesFactory.from_labeled_triples(triples_array)\n",
    "\n",
    "training, validation, testing = full_tf.split([0.8, 0.1, 0.1])\n",
    "\n",
    "results = pipeline(\n",
    "    training=training,\n",
    "    validation=validation,\n",
    "    testing=testing,\n",
    "    model='TransE',\n",
    "    model_kwargs=dict(embedding_dim=50),\n",
    "    training_kwargs=dict(num_epochs=100, batch_size=32),\n",
    "    optimizer_kwargs=dict(lr=0.01),\n",
    "    random_seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df841b",
   "metadata": {},
   "source": [
    "## ðŸ“Š Ã‰tape 6 â€” Ã‰valuation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = results.metric_results.to_dict()\n",
    "for key, value in metrics[\"both\"].items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a43d1",
   "metadata": {},
   "source": [
    "## ðŸ§­ Ã‰tape 7 â€” Visualisation des embeddings (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f215543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "entity_embeddings = results.model.entity_representations[0]().detach().numpy()\n",
    "id_to_label = results.training.entity_labeling.label_to_id.inverse\n",
    "\n",
    "reduced = TSNE(n_components=2, random_state=42).fit_transform(entity_embeddings)\n",
    "labels = list(id_to_label.values())\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(reduced[:, 0], reduced[:, 1], alpha=0.7)\n",
    "for i, label in enumerate(labels):\n",
    "    short_label = label.split(\"/\")[-1]\n",
    "    plt.annotate(short_label, (reduced[i, 0], reduced[i, 1]))\n",
    "plt.title(\"Visualisation des entitÃ©s (TransE Embeddings)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
